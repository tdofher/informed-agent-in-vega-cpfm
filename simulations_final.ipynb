{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"simulations_final.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN15+UpYGcVkDqUjYK3s429"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["def simulate_strategies_basic(agents, n_mc, n_steps, x0_sampler, **kwargs):\n","\n","  x0 = x0_sampler(n_mc)\n","\n","  s = x0[:,0]   \n","  results = list()\n","  for name, agent in agents.items():\n","    results.append(BasicResult(x0, agent))\n","\n","  for i in range(1, n_steps):\n","    with torch.no_grad():\n","      # Here we update the state - update s as a geometric brownian motion\n","      s_step = partial(GBM_step, **kwargs)\n","      s_next = s_step(s=s)\n","\n","      for result in results: \n","        __, x, __, __ = result.agent.step(result.path[-1], n_mc=1, s_next = s_next, **kwargs)\n","            \n","        result.update_result(x)\n","      s = s_next\n","      \n","  return results"],"metadata":{"id":"Wp0Pj-GWSKSq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y9Bfp-08wl5-"},"outputs":[],"source":["def simulate_strategies(agents, n_mc, n_steps, x0_sampler, f_L=None, **kwargs):\n","  \"\"\"\n","  Assumes that all agents had the same variable_fees bool\n","\n","  Parameters\n","  ----------\n","    agents : dict\n","      a dictionary of agent names and agents\n","    n_mc : int\n","      the number of simulations to run\n","    n_steps : int\n","      number of steps to run the simulation for\n","    x0_sampler : partial\n","      the state space sampler to use (should be the same as used for agents)\n","    f_L : float, optional\n","      the liquidity fee to set in the case of a variable fee market. If None\n","      use fees from sampler\n","  \"\"\"\n","    \n","  x0 = x0_sampler(n_mc)\n","\n","  '''\n","  # Start with initial price equal to CPFM price\n","  x0[:,0] = x0[:,1] \n","  s = x0[:,0]\n","  # Leave the pool price, x[:,1], and pool balance, x[:,2], as sampled\n","  # Start with 0 position\n","  x0[:,3] = torch.zeros_like(x0[:,3])\n","  # Leave the general account balance as samples \n","  # TODO: sometimes general account is too low to trade anything\n","  # Start with 0 margin account\n","  x0[:,5] = torch.zeros_like(x0[:,5])\n","\n","  # Manually set fee for market\n","  if list(agents.values())[0].variable_fees and f_L is not None:\n","    x0[:,6] = torch.ones_like(x0[:,6]) * f_L\n","  '''\n","\n","  s = x0[:,0]   \n","  results = list()\n","  for name, agent in agents.items():\n","    if isinstance(agent, ActorCritic):\n","      agent.v.eval()\n","      agent.C.eval()\n","    results.append(AgentResult(x0, agent, name = name))\n","      \n","  for i in range(1, n_steps):\n","    kwargs['t'] = i * kwargs['tau']\n","    with torch.no_grad():\n","        \n","      if kwargs.get('increment_type') == 'Brownian Bridge':\n","        b_next = Brownian_bridge_step(**kwargs)\n","        kwargs['dW'] = b_next.clone() - kwargs['b'].clone()\n","        kwargs['b'] = b_next.clone()\n","      # Here we update the state - update s as a geometric brownian motion\n","      s_step = partial(GBM_step, **kwargs)\n","      s_next = s_step(s=s)\n","\n","      for result in results: \n","        if isinstance(result.agent, ActorCritic):\n","          a, x, u, profit_alpha = result.agent.step(result.path[-1], n_mc=1,\n","                                                    train=False, s_next = s_next, **kwargs)\n","        else:\n","          a, x, u, profit_alpha = result.agent.step(result.path[-1], n_mc=1, s_next = s_next, **kwargs)\n","            \n","        result.update_result(a, x, u, profit_alpha)\n","      \n","      s = s_next\n","    \n","  for result in results:\n","      result.finalize_result()\n","      \n","  return results"]},{"cell_type":"code","source":["def simulate_strategies_var_fees(agents, n_mc, n_steps, x0_sampler, fees, **kwargs):\n","  \"\"\"\n","  Assumes that all agents had the same variable_fees bool\n","\n","  Parameters\n","  ----------\n","    agents : dict\n","      a dictionary of agent names and agents\n","    n_mc : int\n","      the number of simulations to run\n","    n_steps : int\n","      number of steps to run the simulation for\n","    x0_sampler : partial\n","      the state space sampler to use (should be the same as used for agents)\n","    f_L : float, optional\n","      the liquidity fee to set in the case of a variable fee market. If None\n","      use fees from sampler\n","  \"\"\"\n","    \n","  x0 = x0_sampler(n_mc)\n","\n","  '''\n","  # Start with initial price equal to CPFM price\n","  x0[:,0] = x0[:,1] \n","  s = x0[:,0]\n","  # Leave the pool price, x[:,1], and pool balance, x[:,2], as sampled\n","  # Start with 0 position\n","  x0[:,3] = torch.zeros_like(x0[:,3])\n","  # Leave the general account balance as samples \n","  # TODO: sometimes general account is too low to trade anything\n","  # Start with 0 margin account\n","  x0[:,5] = torch.zeros_like(x0[:,5])\n","\n","  # Manually set fee for market\n","  if list(agents.values())[0].variable_fees and f_L is not None:\n","    x0[:,6] = torch.ones_like(x0[:,6]) * f_L\n","  '''\n","\n","  s = x0[:,0]   \n","  results = list()\n","\n","  for fee in fees:\n","    x0[:,6] = fee*torch.ones_like(x0[:,6])   \n","    for name, agent in agents.items():\n","      if isinstance(agent, ActorCritic):\n","        agent.v.eval()\n","        agent.C.eval()\n","        print(x0[0,6])\n","      results.append(AgentResult(x0.clone(), agent, name = name + str(fee)))\n","      \n","  for i in range(1, n_steps):\n","    kwargs['t'] = i * kwargs['tau']\n","    with torch.no_grad():\n","        \n","      if kwargs.get('increment_type') == 'Brownian Bridge':\n","        b_next = Brownian_bridge_step(**kwargs)\n","        kwargs['dW'] = b_next.clone() - kwargs['b'].clone()\n","        kwargs['b'] = b_next.clone()\n","      # Here we update the state - update s as a geometric brownian motion\n","      s_step = partial(GBM_step, **kwargs)\n","      s_next = s_step(s=s)\n","\n","      for result in results: \n","        if isinstance(result.agent, ActorCritic):\n","          a, x, u, profit_alpha = result.agent.step(result.path[-1], n_mc=1,\n","                                                    train=False, s_next = s_next, **kwargs)\n","        else:\n","          a, x, u, profit_alpha = result.agent.step(result.path[-1], n_mc=1, s_next = s_next, **kwargs)\n","            \n","        result.update_result(a, x, u, profit_alpha)\n","      \n","      s = s_next\n","    \n","  for result in results:\n","      result.finalize_result()\n","      \n","  return results"],"metadata":{"id":"4zYvtrKRf0fK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BasicResult():\n","\n","  def __init__(self, x0, agent, name=''):\n","    self.path = [x0]\n","    self.name = name\n","    self.agent = agent\n","\n","  def update_result(self, x):\n","    self.path.append(x)"],"metadata":{"id":"pAWsYbbVMnAl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AgentResult():\n","  \n","  def __init__(self, x0, agent, name = ''):\n","      \n","    self.path = [x0]\n","    self.actions = []\n","    self.PnL = []\n","    self.utility = []\n","    self.name = name\n","    self.agent = agent\n","      \n","  def update_result(self, a, x, u, profit_alpha):\n","    self.PnL.append(profit_alpha)\n","    self.path.append(x)\n","    self.actions.append(a)\n","    self.utility.append(u.reshape(-1))\n","      \n","  def finalize_result(self):\n","    path = torch.stack(self.path, 1)\n","    self.s, self.price, self.sum, self.n, self.g, self.m=\\\n","        path[...,0].cpu(), path[...,1].cpu(), path[...,2].cpu(),\\\n","        path[...,3].cpu(), path[...,4].cpu(), path[...,5].cpu()\n","    if self.agent.variable_fees:\n","      self.f_L = path[...,6].cpu()\n","    self.A_S = self.sum / (1 + self.price)\n","    self.A_B = self.sum * self.price / (1 + self.price)\n","    self.V = self.A_B + self.s*self.A_S # (n_mc, L)\n","    self.actions = torch.stack(self.actions, 1) # (n_mc, L, 3)\n","    self.PnL = torch.stack(self.PnL,1) # (n_mc, L)\n","    self.utility = torch.stack(self.utility, 1) # (n_mc, L)\n","    self.c = self.actions[...,-3:]\n","    self.PnL_cumsum = torch.cumsum(self.PnL, 1)\n","  \n","  def final_profits(self):\n","    return torch.sum(self.PnL,1)\n","\n","  def get_mean_pnl(self):\n","    mean_pnl = torch.mean(self.PnL_cumsum, 0)\n","    std_pnl = torch.std(self.PnL_cumsum, 0)\n","\n","    return mean_pnl, std_pnl\n","\n","  def get_pnl_quantile(self, percent):\n","    low_percent = (1. - percent) / 2.\n","    high_percent = percent + (1. - percent) / 2.\n","    low = torch.quantile(self.PnL_cumsum, low_percent, 0)\n","    high = torch.quantile(self.PnL_cumsum, high_percent, 0)\n","    return low, high\n","\n","  def get_start_of_step_price_differential(self):\n","    return self.s - self.price\n","  \n","  def get_end_of_step_price_differential(self):\n","    return self.s[:,0:-2] - self.price[:,1:-1]"],"metadata":{"id":"Z_I5CAwzvRCI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LZ_COLOURWHEEL = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', \n","                  '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n","\n","\n","def plot_inventory(ax, agent, A_B, A_S, n, g, m):\n","    ax.plot(g, label=r'General Account')\n","    ax.plot(m, label=r'Margin Account')\n","    ax.plot(torch.where(n > 0, n * agent.ts * agent.M_long(A_B, A_S) * agent.l_s,\n","                        -n * agent.ts * agent.M_short(A_B, A_S) * agent.l_s),\n","            '--', label=r'Search Margin')\n","    ax.plot(torch.where(n > 0,  n * agent.ts * agent.M_long(A_B, A_S) * agent.l_r,\n","                        -n * agent.ts * agent.M_short(A_B, A_S) * agent.l_r),\n","            '--', label=r'Release Margin')\n","    ax.set_title(r'Inventory')\n","    ax.set_xlabel('Step')\n","    ax.set_ylabel('Value')\n","    ax.legend()\n","    ax.grid()\n","\n","def plot_inventory_multi(ax, i, results, multi=False):\n","  j = 0\n","  \n","  colours = plt.rcParams['axes.prop_cycle'].by_key()['color']\n","  j = 0\n","  for result in results:\n","    if multi:\n","      ax.plot(result.g[i], '-', label=result.name , # + ' General Account'\n","              color = colours[j])\n","      ax.plot(result.m[i], '--', #label=result.name ,# + ' Margin Account',\n","              color = colours[j])\n","      j += 1\n","\n","    else:\n","      ax.plot(result.g[i], '-', label=' General Account')\n","      ax.plot(result.m[i], '--', label=' Margin Account')\n","      ax.plot(torch.where(result.n[i] > 0,\n","                          result.n[i] * result.agent.ts * result.agent.M_long(result.A_B[i], result.A_S[i]) * result.agent.l_s,\n","                          -result.n[i] * result.agent.ts * result.agent.M_short(result.A_B[i], result.A_S[i]) * result.agent.l_s),\n","              '--', label='Search Margin')\n","      ax.plot(torch.where(result.n[i] > 0,\n","                          result.n[i] * result.agent.ts * result.agent.M_long(result.A_B[i], result.A_S[i]) * result.agent.l_r,\n","                          -result.n[i] * result.agent.ts * result.agent.M_short(result.A_B[i], result.A_S[i]) * result.agent.l_r),\n","              '--', label='Release Margin')\n","\n","  ax.set_title(r'Inventory')\n","  ax.set_xlabel('Step')\n","  ax.set_ylabel('Account Balance')\n","  ax.legend()\n","  ax.grid()\n","\n","\n","def plot_pnl_multi(ax, i, results, multi=False):\n","\n","    for result in results:\n","      PnL = result.PnL.clone()[i].cumsum(0).cpu() \n","      ax.plot(PnL, label = result.name)\n","\n","    ax.set_title('Cumulative PNL')\n","    ax.set_xlabel('Step')\n","    ax.set_ylabel('Cumulative PNL')\n","    if multi:\n","      ax.legend()\n","    ax.grid()\n","\n","def plot_action_multi(ax, i, results, multi=False):\n","  labels = ['Long', 'Short', 'Do Nothing']\n","  for result in results:\n","    for j in range(3):\n","      ax.plot(result.actions[i,:,j].numpy(), '--', label=labels[j])\n","  \n","  ax.set_title('Actions')\n","  ax.set_xlabel('Step')\n","  ax.set_ylabel(r'Action')\n","  ax.legend()\n","  ax.grid()    \n","\n","def plot_action_multi(ax, i, results, multi=False):\n","  labels = ['Long', 'Short', 'Do Nothing']\n","  for result in results:\n","    for j in range(3):\n","      ax.plot(result.actions[i,:,j].numpy(), '--', label=labels[j])\n","  \n","  ax.set_title('Actions')\n","  ax.set_xlabel('Step')\n","  ax.set_ylabel(r'Action')\n","  ax.legend()\n","  ax.grid() \n","\n","def plot_price_multi(ax, i, results, multi=False, colours=LZ_COLOURWHEEL):\n","\n","  j = 0\n","\n","\n","  ax.plot(results[0].s[i], label = 'Reference Price', color = 'black')\n","\n","  for result in results:\n","    A_B = result.A_B[i]\n","    A_S = result.A_S[i]\n","    ax.plot(A_B/ A_S, '--', color = colours[j], label = result.name + ' Price')\n","    j += 1\n","\n","  ax.set_title('Future Price')\n","  ax.set_xlabel('Step')\n","  ax.set_ylabel(r'Price')\n","  ax.legend()\n","  ax.grid() \n","\n","def plot_units_held_multi(ax, i, results, multi=False):\n","  for result in results:\n","    ax.plot(result.n[i].numpy(), '.--', label=result.name)\n","\n","  ax.set_title('Agent Position')\n","  ax.set_xlabel('Step')\n","  ax.set_ylabel('Position')\n","  if multi:\n","    ax.legend()\n","  ax.grid()\n","\n","def make_comparison_plots(agent_results, n_mc, indicies=[], save_fig=False):\n","\n","  for j in range(n_mc):\n","    if len(indicies) <= j:\n","      i = j\n","    else:\n","      i = indicies[j]\n","\n","    print(i)\n","            \n","    fig, ax = plt.subplots(1, 4, figsize=(20, 4))\n","    \n","    plot_units_held_multi(ax[0], i, agent_results, multi=True)\n","    \n","    #plot_action(ax[0], actions[i])\n","    \n","    #plot_pnl(ax[1], PnL[i])\n","\n","    '''\n","    for key, value in agent_results.items():\n","        ax[1].plot(value.value()[i], label=key)\n","        ax[1].legend()\n","    '''\n","\n","    plot_pnl_multi(ax[1], i, agent_results, multi=True)\n","        \n","    plot_price_multi(ax[2], i, agent_results, multi=True)\n","        \n","    plot_inventory_multi(ax[3], i, agent_results, multi=True)\n","    \n","    fig.tight_layout()\n","    if save_fig:\n","      fig.savefig(os.path.join(results_path,str(i)+fig_name))\n","    plt.show()\n","\n","def make_comparison_plots_square(agent_results, n_mc, indicies=[], save_fig=False):\n","\n","  for j in range(n_mc):\n","    if len(indicies) <= j:\n","      i = j\n","    else:\n","      i = indicies[j]\n","\n","    print(i)\n","            \n","    fig, ax = plt.subplots(2, 2, figsize=(15, 10))\n","    \n","    plot_units_held_multi(ax[0,0], i, agent_results, multi=True)\n","    ax[0,0].set_title('(a)')\n","\n","    plot_pnl_multi(ax[0,1], i, agent_results, multi=True)\n","    ax[0,1].set_title('(b)')\n","        \n","    plot_price_multi(ax[1,0], i, agent_results, multi=True)\n","    ax[1,0].set_title('(c)')\n","        \n","    plot_inventory_multi(ax[1,1], i, agent_results, multi=True)\n","    ax[1,1].set_title('(d)')\n","    \n","    fig.tight_layout()\n","    if save_fig:\n","      fig.savefig(os.path.join(results_path,str(i)+fig_name))\n","    plt.show()"],"metadata":{"id":"dGfMem7JzFCv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_ideal_agents(agents_dict, parameters_dict, same_conditions=False):\n","\n","  if same_conditions:\n","    parameters = list(parameters_dict.values())[0]\n","    agent = list(agents_dict.values())[0]\n","\n","    if parameters['market_args']['random_agent_update']:\n","      ideal_agent = IdealOneStepAgentTraders(utility = agent.f, device = device, **parameters['market_args'])\n","    else:\n","      ideal_agent = IdealOneStepAgent(utility =agent.f, device=device, **parameters['market_args'])\n","\n","    agents_dict['Ideal Agent'] = ideal_agent\n","  else:\n","    for name, parameters in parameters_dict.items():\n","      agent = agents_dict[name]\n","      if parameters['market_args']['random_agent_update']:\n","        ideal_agent = IdealOneStepAgentTraders(utility = agent.f, device = device, **parameters['market_args'])\n","      else:\n","        ideal_agent = IdealOneStepAgent(utility =agent.f, device=device, **parameters['market_args'])\n","\n","      agents_dict[name +' Ideal Agent'] = ideal_agent\n","\n","  return agents_dict"],"metadata":{"id":"iRkDFpuVlWxB"},"execution_count":null,"outputs":[]}]}